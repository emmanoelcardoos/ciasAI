{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141d1519-5c0b-4d32-b94b-7219aa43c7a0",
   "metadata": {},
   "source": [
    "# Relatório Final do Projeto de Programacao em Python (ciasAI)\n",
    "\n",
    "\n",
    "\n",
    "## Basic Information\n",
    "\n",
    "- **Título**: Análise de Dados do Projeto em Python\n",
    "\n",
    "  \n",
    "- **Nome**: Emmanoel Cardoso  \n",
    "- **Número do Aluno**: 53570\n",
    "- **GitHub User**:emmanoelcardoos\n",
    "\n",
    "  \n",
    "- **Nome**: Diogo Ferreira\n",
    "- **Número do Aluno**: 55060\n",
    "- **GitHub User**:diogo1lf\n",
    "\n",
    "  \n",
    "- **Nome**: Kevin Llulluna \n",
    "- **Número do Aluno**: 53564\n",
    "- **GitHub User**: leobermudez10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefe7e1-234e-4442-a988-d506f23a8698",
   "metadata": {},
   "source": [
    "## Contribution\n",
    "\n",
    "### Diogo Ferreira\n",
    "- **Responsabilidades**:\n",
    "  - Análise de Sentimento: Contar o número de tweets por sentimento (positivo, negativo, neutro).\n",
    "  - Análise de Sentimento: Calcular a percentagem de cada tipo de sentimento para todas as companhias aéreas.\n",
    "  - Análise de Sentimento: Identificar a companhia aérea com o maior número de tweets positivos.\n",
    "  - Análise de Sentimento: Analisar o número médio de retweets por tipo de sentimento.\n",
    "- **Esforço (horas)**: 2 horas.\n",
    "- **Descrição detalhada**: A ser preenchida após a realização das tarefas.\n",
    "\n",
    "### Kevin Llulluna\n",
    "- **Responsabilidades**:\n",
    "  - Análise de Companhias Aéreas: Listar todas as companhias aéreas mencionadas no dataset.\n",
    "  - Análise de Companhias Aéreas: Identificar a companhia com mais tweets negativos.\n",
    "  - Análise de Companhias Aéreas: Calcular o número total de tweets por companhia.\n",
    "  - Análise de Companhias Aéreas: Filtrar os tweets de uma companhia específica e mostrar seus detalhes.\n",
    "- **Esforço (horas)**: 2 horas.\n",
    "- **Descrição detalhada**: A ser preenchida após a realização das tarefas.\n",
    "\n",
    "### Emmanoel Cardoso\n",
    "- **Responsabilidades**:\n",
    "  - Processamento Temporal: Identificar o dia com maior número de tweets.\n",
    "  - Processamento Temporal: Contar quantos tweets foram feitos num determinado mês ou ano.\n",
    "  - Leitura de Dados: Implementar uma função para ler o ficheiro CSV e armazenar os dados numa estrutura apropriada.\n",
    "  - Criação do PackagePython\n",
    "  - Criacao e Publicação do repositório no GitHub\n",
    "  - Criação do Relatório\n",
    "  - Criacao de Arquivos necessarios para a execucao do pacote como: setup, unit e ficheiros README\n",
    "- **Esforço (horas)**: 6 horas.\n",
    "- **Descrição detalhada**: Trabalhou na construção das funções para ler os dados do arquivo csv e processamento temporal. Trabalhou tambem na criação deste relatório além da criação do pacote e repositório.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a47ef3-640c-4856-b262-7685f5296e73",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Este projeto de programação é uma atividade realizada por Emmanoel Cardoso, Kevin Llulluna e Diogo Ferreira, que tem como objetivo reforçar e aplicar os conceitos aprendidos durante a Unidade Curricular. O principal propósito foi desenvolver um package em Python capaz de realizar a leitura, processamento e análise de um dataset contendo tweets sobre companhias aéreas dos Estados Unidos. O dataset, fornecido pelo docente da cadeira e denominado Twitter US Airline Sentiment, apresenta informações sobre os sentimentos expressos em tweets relacionados às companhias aéreas.\n",
    "\n",
    "A solução que encontramos foi filtrar os tweets de avaliações do dataset, com o objetivo de ajudar as companhias aéreas estadunidenses a melhorar seus serviços com base nas opiniões indiretas de seus clientes.\n",
    "\n",
    "Com este projeto, esperamos que os dados do dataset sejam processados para permitir:\n",
    "\n",
    "- Análise de sentimentos dos passageiros.\n",
    "- Identificação das companhias aéreas mais comentadas.\n",
    "- Processamento temporal, que poderá ajudar as companhias a identificar avaliações específicas, especialmente durante períodos de alta # demanda, como feriados e festividades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38ce5-026d-4d55-8de0-961fe7e5d68e",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "No desenvolvimento deste projeto, as principais estruturas de dados utilizadas são listas e dicionários, que são adequadas para lidar com os dados dos tweets no formato CSV.\n",
    "\n",
    "1. **Lista de Dicionários**:\n",
    "   - **Estrutura**: A principal estrutura utilizada para armazenar os dados dos tweets é uma lista de dicionários. Cada tweet é representado por um dicionário, onde as chaves correspondem aos campos do CSV (como airline, airline_sentiment, tweet_created, etc.), e os valores são os dados reais desses campos.\n",
    "   - **Justificativa**: O uso de listas permite uma organização sequencial dos tweets, mantendo a ordem de chegada ou de coleta. Já os dicionários proporcionam acesso rápido aos valores associados a cada campo, permitindo uma análise eficiente e fácil de manipulação dos dados. Isso facilita a contagem de sentimentos, a filtragem por companhia aérea, e o cálculo de percentuais de sentimentos por companhia.\n",
    "   \n",
    "2. **Counter (do módulo collections)**:\n",
    "   - **Estrutura**: A estrutura Counter é usada para contar a frequência de certos valores, como os sentimentos (positivos, negativos, neutros) ou as companhias aéreas mais mencionadas.\n",
    "   - **Justificativa**: O Counter é ideal para essas tarefas, pois é otimizado para realizar contagens rápidas de elementos em listas ou outros iteráveis. Isso é útil na contagem de tweets por sentimento e na identificação da companhia aérea mais mencionada com tweets positivos.\n",
    "\n",
    "3. **defaultdict (do módulo collections)**:\n",
    "   - **Estrutura**: O defaultdict é utilizado para agrupar dados de sentimento por companhia aérea, onde cada chave é uma companhia e o valor é um Counter que mantém a contagem de sentimentos.\n",
    "   - **Justificativa**: O uso do defaultdict simplifica o código, já que ele automaticamente cria novos dicionários ou contadores para novas chaves, eliminando a necessidade de verificações extras para inicializar as contagens de sentimentos.\n",
    "\n",
    "Essas estruturas de dados foram escolhidas devido à sua eficiência e flexibilidade para manipulação de dados de texto, contagem e agrupamento. Elas oferecem boa performance e simplicidade na implementação das funcionalidades do projeto.\n",
    "\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae52a6-48cb-46b4-80e1-d8e350701004",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "A função principal responsável pelo carregamento dos dados do dataset é a \"open_file\", localizada no módulo \"leitor_dados\". Esta função é responsável por ler os dados de um arquivo CSV e retorná-los como uma lista de dicionários, onde cada dicionário representa uma linha do arquivo com os campos e seus respectivos valores.\n",
    "\n",
    "- **Função \"open_file**\n",
    "\n",
    "- **Propósito**: A função \"open_file\" recebe o caminho de um arquivo CSV como parâmetro e utiliza o módulo \"csv\" do Python para ler o conteúdo do arquivo. Ela converte cada linha do CSV em um dicionário, onde as chaves correspondem aos cabeçalhos das colunas do arquivo, e os valores são os dados da respectiva linha. Ao final, a função retorna uma lista contendo todos os dicionários, que pode ser facilmente manipulada no processo de análise dos dados.\n",
    "\n",
    "- **Exemplo de uso**:\n",
    "  ```python\n",
    "  from ciasAI.leitor_dados import open_file\n",
    "\n",
    "  file_path = \"/path/to/Tweets.csv\"  # Caminho para o arquivo\n",
    "  data = open_file(file_path)\n",
    "\n",
    "  if data:\n",
    "      print(\"Dados carregados com sucesso!\")\n",
    "  else:\n",
    "      print(\"Erro ao carregar os dados.\")\n",
    "\n",
    "**Dificuldades Encontradas**: Podem haver os seguintes erros durante a execucao desta funcao: \n",
    "- 1 : Arquivo nao encontrado caso não seja definida o caminho do fciheiro Tweets.csv a qual será lido\n",
    "- 2 : Erro de formatacao do arquivo Tweets.csv\n",
    "- 3 : Problema de codificacao diferente da UTF-8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01daca6-5a3d-4877-9e4d-d5cdddd18105",
   "metadata": {},
   "source": [
    "## Processamento e análise de dados\n",
    "\n",
    "O propósito principal do processamento e análise é transformar os dados brutos do dataset em informações relevantes, identificando padrões, tendências e insights que possam auxiliar no entendimento do sentimento dos usuários em relação às companhias aéreas nos Estados Unidos.\n",
    "As funções utilizadas no projeto realizam etapas como filtragem, contagem de sentimentos, análise temporal dos dadose analise das cias aereas.\n",
    "\n",
    "\n",
    "- 1. **Função open_file (módulo leitor_dados)**\n",
    "\n",
    "  - Propósito: Essa função tem como objetivo carregar os dados de um arquivo CSV e retorná-los como uma lista de dicionários, onde cada dicionário representa uma linha do arquivo com seus respectivos valores.\n",
    "  - Exemplo de uso:\n",
    "  - Insight: Ao carregar os dados, podemos analisar tweets de várias companhias aéreas. Caso o arquivo seja carregado com sucesso, podemos continuar a análise, como calcular sentimentos ou filtrar tweets de companhias específicas.\n",
    "      \n",
    "- 2. **Função contador_sentiment (módulo analise_sentimento)**:\n",
    "\n",
    "  - Propósito: Essa função tem como objetivo contar a quantidade de tweets para cada sentimento (positivo, negativo, neutro) presente nos dados, permitindo analisar a distribuição de sentimentos nas menções às companhias aéreas.\n",
    "  - Insight: Counter({'positive': 300, 'negative': 150, 'neutral': 50})\n",
    " \n",
    "    \n",
    "- 3: **Função positive_tweet (módulo analise_sentimento)**\n",
    "\n",
    "  \n",
    "    - Propósito: Essa função encontra a companhia aérea que recebeu o maior número de tweets positivos.\n",
    "    - Insight: \"A companhia aérea 'Delta' foi a mais mencionada com sentimentos positivos.\"\n",
    "      \n",
    "   \n",
    "- 4: **Função porcentage_sentimento (módulo analise_sentimento)**:\n",
    "\n",
    "  \n",
    "    - Propósito: Calcula a percentagem de tweets com cada sentimento para cada companhia aérea.\n",
    "    - Insight: \"A companhia 'Delta' tem 60% de tweets positivos, enquanto a 'United' tem apenas 40%. Já a 'United' tem 50% de tweets negativos.\"\n",
    "      \n",
    "   \n",
    "- 5: **Função filtro_tweet (módulo analise_sentimento)**:\n",
    "\n",
    "    - Propósito: Filtra os tweets de uma companhia aérea específica.\n",
    "    - Insight: Após filtrar os tweets da Delta, podemos observar o conteúdo dos tweets e fazer uma análise qualitativa sobre o que está sendo falado sobre essa companhia. Isso pode revelar tendências e opiniões populares sobre ela. O que ajuda a companhia a tomar decisoes de melhorias\n",
    "      \n",
    "\n",
    "- 6: **Função realizar_login (módulo analise_cia)**:\n",
    "\n",
    "    - Propósito: Essa função realiza um login simples com validação de usuário e senha.\n",
    "    - Insight: \"Acesso autenticado com sucesso para o usuário 'main'.\"\n",
    "      \n",
    "\n",
    "- 7: **Função total_tweets_por_companhia (módulo analise_cia)**:\n",
    "\n",
    "    - Propósito: Conta o número total de tweets para cada companhia aérea.\n",
    "    - Insight: \"A companhia 'Delta' recebeu o maior número de tweets, com 400 menções, seguida pela 'United' com 300.\"\n",
    "\n",
    "- 8: **Função listar_companhias (módulo analise_cia)**\n",
    "\n",
    "  - Propósito: Lista todas as companhias aéreas presentes nos dados.  \n",
    "  - Insight: \"As companhias aéreas presentes nos dados são: Delta, United, American e Southwest.\"\n",
    "\n",
    "\n",
    "\n",
    "- 9: **Função filtrar_tweets_por_companhia (módulo analise_cia):**\n",
    "\n",
    "  - Propósito: Filtra os tweets de uma companhia aérea específica.  \n",
    "  - Insight: A função retorna os tweets relacionados à Delta, permitindo analisar como os clientes estão interagindo com ela. Isso pode ser usado para avaliar a percepção pública dessa companhia.\n",
    "\n",
    "\n",
    "- 10: **Função companhia_com_mais_tweets_negativos (módulo analise_cia)**\n",
    "\n",
    "  - Propósito: Encontra a companhia aérea com o maior número de tweets negativos. \n",
    "  - Insight: \"A companhia aérea 'United' foi a mais mencionada com tweets negativos.\"\n",
    "\n",
    "\n",
    "- 11: **Função carregar_dados (módulo processamento_temporal):**\n",
    "\n",
    "  - Propósito: Carrega os dados de tweets e converte o campo de data para o tipo datetime.\n",
    "  - Insight: Carregar os dados corretamente é um passo essencial para realizar qualquer análise temporal dos tweets, como contar tweets por período ou identificar o dia com mais tweets.\n",
    "\n",
    "\n",
    "- 12: **Função contar_tweets_por_periodo (módulo processamento_temporal)**\n",
    "\n",
    "  - Propósito: Conta o número de tweets em um ano específico, podendo também filtrar por mês.\n",
    "  - Insight: \"Em janeiro de 2023, houve 120 tweets.\"\n",
    "\n",
    "- 13: **Função dia_com_mais_tweets (módulo processamento_temporal)**:\n",
    "\n",
    "  - Propósito: Identifica o dia com o maior número de tweets.\n",
    "  - Insight: Insight: \"O dia com mais tweets foi 15 de janeiro de 2023, com 45 tweets.\"\n",
    "\n",
    "**Observacao importante:** Alguns insight poderao retornar outros valores conforme a funcao seja chamada ou definida pela o usuario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e3e5-9f6f-44bd-b047-78ef44c1207b",
   "metadata": {},
   "source": [
    "## Logs\n",
    "\n",
    "O sistema de logs foi implementado utilizando o módulo logging do Python, com o objetivo de registrar e monitorar as atividades realizadas pelo sistema, especialmente durante as operações críticas, como o processo de login e as análises de dados.\n",
    "\n",
    "- **Configuração do Log:**\n",
    "\n",
    "A configuração do sistema de logs é realizada no módulo analise_cia, onde o arquivo de log é configurado para ser salvo com o nome login.log. A seguir, apresentamos as configurações:\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='login.log', level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3d216-222f-453b-8fa7-2ca558c3f7e9",
   "metadata": {},
   "source": [
    "## Asserts e Exceções\n",
    "\n",
    "**Exceções**\n",
    "\n",
    "As exceções são usadas para tratar erros de maneira controlada, evitando falhas abruptas no programa. No projeto, a função open_file, responsável por carregar os dados de um arquivo CSV, utiliza blocos try...except para capturar erros como arquivos não encontrados ou outros problemas ao processar os dados. Caso um erro aconteça, uma mensagem de erro é exibida, e a função retorna None para indicar falha no carregamento dos dados.\n",
    "\n",
    "**Asserts**\n",
    "\n",
    "Os asserts são usados para verificar condições durante a execução do código e levantar erros caso uma condição esperada não seja atendida. No entanto, neste projeto, não foi feito uso extensivo de asserts, mas poderiam ser adicionados para garantir, por exemplo, que os dados estejam no formato correto antes de prosseguir com o processamento. Asserts ajudam a validar pressupostos no código, especialmente durante a fase de desenvolvimento e testes.\n",
    "\n",
    "**Conclusão**\n",
    "\n",
    "As exceções foram utilizadas no projeto para garantir que erros críticos sejam tratados de maneira adequada, sem interromper o fluxo do programa. Embora não tenha sido amplamente utilizado, o uso de asserts poderia ser implementado para validações adicionais, aumentando a eficiencia do código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc14ca-29a5-4cd7-b34b-f9d6c60344b5",
   "metadata": {},
   "source": [
    "## Declaração de Honra e Integridade Académica\n",
    "\n",
    "Eu, Emmanoel Cardoso, estudante com o número de inscrição 53570 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024\n",
    "\n",
    "Eu, Kevin LLulluna, estudante com o número de inscrição 53564 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024\n",
    "\n",
    "Eu, Diogo Ferreira, estudante com o número de inscrição 55060 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa21a3-72e3-46a4-adee-8db8f97aaed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
